{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def mean_squared_error(y_pred, y_true):\n",
    "    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)\n",
    "    \n",
    "def accuracy(y_pred, y_true):\n",
    "    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from files\n",
    "tra = pd.read_csv(\"optdigits.tra\",header=None)\n",
    "x_train = tra.values[:,:64]\n",
    "y_training = tra.values[:,-1]\n",
    "\n",
    "tes = pd.read_csv(\"optdigits.tes\",header=None)\n",
    "x_test = tes.values[:,:64]\n",
    "y_testing = tes.values[:,-1]\n",
    "\n",
    "y_train = pd.get_dummies(y_training).values\n",
    "y_test = pd.get_dummies(y_testing).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "learning_rate = 10\n",
    "iterations = 2000\n",
    "N = y_train.size\n",
    "\n",
    "# number of input features\n",
    "input_size = 64\n",
    "\n",
    "# number of hidden layers neurons\n",
    "hidden_size = 20\n",
    "\n",
    "# number of neurons at the output layer\n",
    "output_size = 10  \n",
    "\n",
    "results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "np.random.seed(10)\n",
    "\n",
    "# initializing weight for the hidden layer\n",
    "W1 = np.random.normal(scale=1, size=(input_size, hidden_size))   \n",
    "\n",
    "WH = np.random.normal(scale=1, size=(hidden_size, 2)) \n",
    "\n",
    "# initializing weight for the output layer\n",
    "W2 = np.random.normal(scale=1, size=(2 , output_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr in range(iterations):    \n",
    "    \n",
    "    # feedforward propagation\n",
    "    # on hidden layer\n",
    "    Z1 = np.dot(x_train, W1)\n",
    "    A1 = sigmoid(Z1)\n",
    "    # print(A1.shape)\n",
    "    # second hidden layer\n",
    "    ZH = np.dot(A1, WH)\n",
    "    AH = sigmoid(ZH)\n",
    "    # print(AH.shape)\n",
    "\n",
    "    # on output layer\n",
    "    Z2 = np.dot(AH, W2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    # print(A2.shape)\n",
    "    \n",
    "    # Calculating error\n",
    "    mse = mean_squared_error(A2, y_train)\n",
    "    acc = accuracy(A2, y_train)\n",
    "    results=results.append({\"mse\":mse, \"accuracy\":acc},ignore_index=True )\n",
    "    \n",
    "    # backpropagation\n",
    "    E1 = A2 - y_train\n",
    "    dW1 = E1 * A2 * (1 - A2)\n",
    "    # print(dW1.shape)\n",
    "    EH = np.dot(dW1, W2.T)\n",
    "    dWH = EH * AH * (1 - AH)\n",
    "    # print(dWH.shape)\n",
    "    E2 = np.dot(dWH, WH.T)\n",
    "    dW2 = E2 * A1 * (1 - A1)\n",
    "    # print(dW2.shape)\n",
    "    \n",
    "    # weight updates\n",
    "    WH_update = np.dot(A1.T,dWH) / N \n",
    "    # print(WH_update.shape)\n",
    "    W2_update = np.dot(AH.T, dW1) / N\n",
    "    # print(W2_update.shape)\n",
    "    W1_update = np.dot(x_train.T, dW2) / N\n",
    "    # print(W1_update.shape)\n",
    "    W2 = W2 - learning_rate * W2_update\n",
    "    W1 = W1 - learning_rate * W1_update\n",
    "    WH = WH - learning_rate * WH_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mse.plot(title=\"Mean Squared Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.accuracy.plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedforward\n",
    "Z1 = np.dot(x_test, W1)\n",
    "A1 = sigmoid(Z1)\n",
    "\n",
    "\n",
    "Z2 = np.dot(A1, W2)\n",
    "A2 = sigmoid(Z2)\n",
    "\n",
    "acc = accuracy(A2, y_test)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(A1[:100,:])\n",
    "for i in range(0,10):\n",
    "    x = A1[y_testing == i]\n",
    "    plt.scatter(x[:, 0], x[:, 1 ],alpha=0.6,s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
